\section{Motivations}

The exascale era of High-Performance Computing (HPC) will come soon, and the first exascale machine will be available around 2020, in which, the researchers hope to make unprecedented advancements in many fields of sciences and industries. In fact, the most powerful machines now around the world have already over a million cores. With the introduction of the Graphics Processing Unit (GPU) and other accelerators, the HPC cluster systems will continue not only to scale up in compute node and Central Processing Unit (CPU) core count, but also increase the heterogeneity of components. This trend causes the transition to multi- and many cores inside of computing nodes which communicate explicitly through faster interconnection networks. These hierarchical supercomputers can be seen as the combination of distributed and parallel computing. Nevertheless, only a small number of applications may attain sustainable performances due to their lack of good scalability on large clusters. 

Many scientific and industrial applications can be formulated as linear systems. A linear system can be described by an operator matrix $A$, an input $x$ and an output $b$. The linear solvers which aim to solve these systems, are the kernels of many simulation applications and softwares. When the operator matrix A is sparse, the collection of Krylov subspace methods, e.g., the Generalized minimal residual method (GMRES), the Conjugate Gradient (CG)  and the Biconjugate Gradient Stabilized Method (BiCGSTAB), are well-known algorithms to solve the linear systems. The Krylov subspace methods can approximate the exact solution of a linear system through the Krylov subspace starting from a given initial guess vector.

Linear systems are used to describe the real-world applications, such as the fusion reactions, the earthquake, and weather forecasts, etc., and as their application complexity increases, their dimension grows rapidly, e.g., more than $10$ billions unknows for the earthquake simulation. Hence, Krylov subspace methods should be deployed on the supercomputing platforms to solve such large-scale linear systems. Nowadays, with the increase of computing unit number and the heterogeneity of supercomputers, the communication of overall reduction and global synchronization of Krylov subspace methods are a bottleneck, which damages their parallel performance heavily. In details, when solving a large-scale problem on parallel architectures by Krylov subspace methods, their cost per iteration becomes the most significant concern, typically because of communication and synchronization overhead. Consequently, large scalar products, overall synchronization, and other operations involving communications among all cores have to be avoided. The parallel implementation of numerical algorithms should be optimized for more local communications and less global communications. In order to benefit the full computational power of such hierarchical computing systems, it is central to explore novel parallel methods and models for solving linear systems. These methods should not only be able to accelerate the convergence but also have the abilities to adapt to multi-grain, multi-level memory, to improve the fault tolerance, reduce synchronization and promote asynchronization.

\section{Objectives and Core Contributions}

The subject of this dissertation fits within this research context, and it focuses on the proposition and analysis of a distributed and parallel programming paradigm for smart hybrid Krylov methods targetting at the exascale computing. The research relies on the Unite and Conquer (UC) approach proposed by Emad \cite{emad2016unite}. This approach is a model for the design of numerical methods by combining different computation components to work for the same objective, with asynchronous communication among them. These different components can be deployed on different platforms such as P2P, cloud and the supercomputer systems, or different processors of the same platform. The idea of UC approach came from the article of Saad \cite{saad1984chebyshev} where he suggested using Chebyshev polynomial to accelerate the convergence of Explicitly Restarted Arnoldi Method (ERAM) to solve eigenvalue problems. The ingredients of this dissertation to construct a Unite and Conquer linear solver come from the previous research of hybrid methods, e.g., a hybrid Chebyshev Krylov subspace algorithm proposed by Elman \cite{elman1986hybrid}, a hybrid GMRES algorithm via a Richardson iteration with Leja ordering \cite{nachtigal1992hybrid}, an approach for solving a system of linear equations which takes a combination of two arbitrary approximate solutions of two methods introduced by Brezinski \cite{brezinski1994hybrid}, and a hybrid gmres/ls-arnoldi method firstly proposed by Essai \cite{essai1999heterogeneous}.

Before the investigation on the Krylov subspace methods to solve linear systems, the first contribution of this work is to develop a Scalable Matrix Generator with Given Spectra (SMG2S), due to the importance of spectral distribution on the convergence of iterative methods. SMG2S allows generating large-scale non-Hermitian matrices with user-customized eigenvalues. These generated matrices are also non-Hermitian and non-trivial, with very high dimensions. Recent research related to social networking, big data, machine learning, and artificial intelligence has increased the necessity for non-hermitian solvers associated with much larger sparse matrices and graphs. Iterative linear algebra methods are important parts of the overall computing time of applications in various fields since decades. The analysis of the behaviors of iterative methods for such problems is complex, and it is necessary to evaluate their numerical and parallel performances to solve extremely large non-Hermitian eigenvalue and linear problems on parallel and/or distributed machines. Since the properties of spectra have impacts on the convergence of iterative methods , it is necessary to generate large matrices with known spectra to benchmark them. The motivation to propose SMG2S is that there is currently no set of test matrices with large dimension and different kinds of spectral properties to benchmark the linear solvers on supercomputers. SMG2S serves as a important tool during my thesis to study the performance of new design iterative methods.

After the implementation of SMG2S, the second contribution of my dissertation is to design and implement an asynchronous Unite and Conquer GMRES/LS-ERAM (UCGLE) method based on the UC approach. UCGLE is proposed to solve large-scale linear systems with the reduction of global communications. Most of the hybrid and deflated iterative methods are able to be transformed into distributed and parallel schema based on the UC approach. However, this dissertation only implements UCGLE as an example based on a hybrid method preconditioned by Least Squares polynomial. UCGLE consists of three computation components: ERAM Component, GMRES Component, and LSP (Least Squares Polynomial) Component. GMRES Component is used to solve the systems, LSP Component and ERAM Component serve as the preconditioning part. The materials for accelerating the convergence are the eigenvalues. The critical feature of this hybrid method is the asynchronous communication among these three components, which reduces the number of overall synchronization points and minimizes global communications. There are three levels of parallelisms in UCGLE method to explore the hierarchical computing architectures. The convergence acceleration of UCGLE method is similar to a deflated preconditioner. The difference between them is that the improvement of the former one is intrinsic to the methods. It means that in the deflated preconditioning methods, for each time of preconditioning, the solving procedure should stop and wait for the temporary preconditioning procedure. Asynchronous communications of the latter can cover the synchronization overhead. The asynchronous communications among the different computational components also improve the fault tolerance and the reusability of this method. 

% With the help of asynchronous communications, we can select to save the computed eigenvalues by ERAM method into a local file and reuse them for solving the other linear systems which have the same operator matrix, but different right-hand side (RHS), and the reusability of linear solvers can be improved.

Moreover, both the mathematical model and the implementation of UCGLE are extended to solve linear systems in sequence which share the same operator matrix $A$ but have different Right-hand sides (RHSs) $b$. The eigenvalues obtained in solving previous systems by UCGLE can be recycled, improved on the fly and applied to construct a new initial guess vector for subsequent linear systems, which can achieve a continuous acceleration to solve linear systems in sequence. Numerical experiments using different test matrices to solve sequences of linear systems on supercomputers indicate a substantial decrease in both computation time and iteration steps when the approximate eigenvalues are recycled to generate the initial guess vectors.

Afterward, since many problems in the field of science and engineering often require to solve simultaneously large-scale linear systems with multiple RHSs, we propose an extension of UCGLE by combining it with Block GMRES (BGMRES) method. This variant of UCGLE is implemented with novel manager engine, which is capable of allocating multiple Block GMRES at the same time, each Block GMRES solving the linear systems with a subset of RHSs and accelerating the convergence using the eigenvalues approximated by eigensolvers. Dividing the entire linear system with multiple RHSs into subsets and solving them simultaneously with different allocated linear solvers allow localizing calculations, reducing global communication, and improving parallel performance. Meanwhile, the asynchronous preconditioning using eigenvalues is able to speed up the convergence. 

%Numerical experiments using different test matrices on supercomputers indicate that the proposed method achieves a substantial decrease in both computation time and iterative steps with good scaling performance.

%Eventually, an adaptive UCGLE is proposed which gives the scheme of auto-tuning the complex parameters inside which have the influence on its numerical and parallel performance. This work was achieved by analyzing the impacts of different parameters on the convergence.

\section{Outline}

The dissertation is organized as follows. In Chapter \ref{State-of-the-art in High-Performance Computing}, we will give the state-of-the-art of HPC, including the modern computing architectures for supercomputers (e.g., CPU, Nvidia GPGPU, and Intel Many Integrated Cores) and the parallel programming model (including OpenMP, CUDA, MPI, PGAS, the task/graph based programming, etc.). Finally, in this chapter, we will talk about the current challenges of HPC facing the coming of exascale supercomputers.

Chapter \ref{Krylov Subspace Methods} covers the existing iterative methods for solving linear systems and eigenvalue problems, especially the Krylov Subspace methods. Firstly, this chapter gives a brief introduction of the stationary and non-stationary iterative methods. Then different Krylov Subspace methods will be presented and compared. Apart from the basic presentation of methods, different preconditioners used to accelerate the convergence will be discussed, especially a Least Squares Polynomial method which is used to construct UCGLE, will be introduced in details. The relation between the convergence of Krylov subspace methods for solving linear systems and the spectral information of operator matrix $A$ will also be analyzed in this chapter. Finally, we give a brief introduction of the parallel implementation of the Krylov subspace methods on modern distributed memory systems, then discuss the challenges of iterative methods facing on the coming of exascale platforms, and finally summarize the recent efforts to fit the numerical methods to the much more larger clusters/supercomputers.

%SMG2S can generate large-scale non-Hermitian test matrices using the user-defined spectrum and ensuring their eigenvalues as the given ones with high accuracy.

In Chapter \ref{Sparse Matrix Generator with Given Spectra}, we present the parallel implementation and numerical performance evaluation of SMG2S. It is implemented on CPUs and multi-GPU platforms with specifically optimized communications. Good strong and weak scaling performance is obtained on several supercomputers. We also propose a method to verify its ability to guarantee the given spectra base on the shift inverse power method. SMG2S is a released open source software which is developed using MPI and C++11. Finally, the packaging, the interfaces to other programming languages and scientific softwares, and the graphic user interface (GUI) for verification are introduced in this chapter.

In Chapter \ref{Unite and Conquer GMRES/LS-ERAM Method}, the implementation of UCGLE based on the scientific libraries PETSc and SLEPc for both CPUs and GPUs are presented. In this chapter, we describe the implementation of components, the manager engine, and the distributed and parallel asynchronous communications. After the implementation, the selected parameters, the convergence, the impact of spectral distribution, the scalability and fault tolerance are evaluated on several supercomputers.

Chapter \ref{UCGLE for Linear Systems with Sequences of Right-hand-sides} presents the extension of UCGLE to solve linear systems in sequence with different RHSs by recycling the eigenvalues. Firstly, we give a survey of existing algorithms, including the seed and deflated methods, and then develop the mathematical model and manager engine of UCGLE to solve linear systems in sequence. The experimental results of the evaluation on different supercomputers are also shown in this chapter.

The variant of UCGLE to solve simultaneously linear systems with multiple RHSs is presented in Chapter \ref{UCGLE for Linear Systems with Multiple Right-hand-sides}. Firstly, this chapter introduces the existing block methods to solve linear systems with multiple RHSs, and then analyzes the limitations of block methods on large-scale platforms. After that, a mathematical extension of Least Squares polynomial for multiple RHSs is given, and then the implementation of the special novel manager engine is presented. This engine allows allocating multiple GMRES and ERAM Components at the same time. This special version of UCGLE is implemented with the block GMRES provided by the Belos and Anasazi packages of Trilinos. Finally, we give the experimental results on large-scale machines.

UCGLE is a hybrid method with the combination of three different numerical methods. Thus the autotuning of different parameters is very important. In Chapter \ref{Parameters Autotuning}, we propose the strategy of autotuning for parameters. %\textcolor{red}{(to be developed)}

All Unite and Conquer methods including UCGLE, are able to implement using the workflow/task based programming runtimes to manager the fault tolerance, load balance, asynchronous communications of signals, arrays and vectors and the management of different computing units such as GPUs. In Chapter \ref{YML and XMP Multi-level Parallelism Programming Paradigm}, we give a glance at the YML framework, and then analyze the workflow of UCGLE methods and the limitations of YML for UC approach. Finally, we propose the solutions of grammar and implementation for YML, including the dynamic graph grammar, and the mechanism of exiting a parallel branch.

In Chapter \ref{Conclusion and Pespectives}, we summarize the key results obtained in this thesis and present our concluding remarks. Finally, we suggest some possible paths to future research.
